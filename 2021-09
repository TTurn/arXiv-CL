Beyond Preserved Accuracy: Evaluating Loyalty and Robustness of BERT  Compression
标题：超越保留的准确性：评估BERT压缩的忠诚度和稳健性
链接：https://arxiv.org/abs/2109.03228
摘要：最近关于预训练语言模型（例如，BERT）压缩的研究通常使用保留精度作为评估指标。
在本文中，我们提出了两个新的度量标准，标签忠诚和概率忠诚，用于衡量压缩模型（即学生）与原始模型（即教师）的模仿程度。
我们还探讨了在对抗性攻击下压缩对鲁棒性的影响。我们将量化、剪枝、知识提炼和渐进式模块替换为忠诚和健壮性。通过结合多种压缩技术，我们提供了一种实用的策略，以实现更好的准确性、忠诚度和鲁棒性。
